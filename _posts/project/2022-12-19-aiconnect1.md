---
title: "[ai-connect] 암 예후예측 경진대회 1편 준비 및 config.yaml load"
excerpt: "암 환자에 대한 임상 및 병리 정보를 기반으로 Survival Analysis를 하는 대회 1편"

published: true

categories:
  - Project

tags: [ai-connect, 공모전, project, Survival Analysis, pycox]

toc: true
toc_sticky: true

date: 2022-12-19 17:05:00
last_modified_at: 2022-12-19 17:05:00
---

<br>

본 대회는 아주대학교 산학협력단에서 주관하고 ai-connect 플랫폼에서 진행되었다. 대회 기간이 5일에 불과하였고, 마침 이미 진행중이던 대회가 입상이 확정되었던 때라 조금 여유를 가지고 참여할 수 있었다.

대회에 대한 설명은 아래와 같다.

<img src="https://user-images.githubusercontent.com/115082062/208376561-df00610d-efaf-4625-b11d-6d3b634214af.png">

본 대회는 환자의 임상, 병리 데이터를 가지고 암 예후예측을 하는 생존분석 과제였다. Survival Analysis(생존분석)은 통계학의 한 분야로, 어떠한 현상이 발생하기까지 걸리는 시간을 예측하는 분야이다.

실제 병리 임상데이터를 활용하는 것으로 외부 반출이 엄격히 금지되었다. 그러한 문제로 인해 인터넷이 차단된 리눅스 터미널에서 개발을 해야 했다. 때문에 vim으로 코딩을 해야 하는 번거로움을 감수했다. 덕분에 vim과 터미널에 익숙해지는 공부 효과가 있었다.

대회에서 사용한 알고리즘은 pycox 모듈의 CoxPH였다. pytorch를 기반으로 하는 모듈인데, 관련 정보가 거의 없어서 모델을 개발하는 데에 애를 먹었다. 하지만 대회 측에서 베이스라인을 제공해준 덕분에 나름 수월하게 작업할 수 있었다.

## 라이브러리, 모듈 설치

```python
import os, sys
import random
import argparse
from datetime import datetime, timezone, timedelta
import numpy as np
import pandas as pd
import dill as pickle

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn_pandas import DataFrameMapper
from sklearn.preprocessing import PolynomialFeatures
import torch
import torchtuples as tt
import torchtuples.callbacks as cb
from torch import nn

from pycox.datasets import metabric
from pycox.models import CoxPH
from pycox.evaluation import EvalSurv

prj_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(prj_dir)
```

modules는 함수를 저장해놓는 용도로 만든 터미널 내 디렉토리이다. trainer는 모델 학습과 관련된 함수를 저장해놓고, utils는 그 외 여러 기능의 함수를 저장해놓는다.

```python
from modules.utils import load_yaml, get_logger, save_yaml, save_pkl
from modules.trainer import fit
```

<br>

## config 정보 불러오기

모델 개발에 쓰이는 파라미터들을 train_config.yaml 파일에 작성해놓고, 이를 가져다 쓰는 식으로 진행된다. 때문에 다른 디렉토리에 있는 yaml 파일을 로드하는 과정이 필요하다.
```python
PROJECT_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_PROJECT_DIR = os.path.dirname(PROJECT_DIR)

TRAIN_CONFIG_PATH = os.path.join(PROJECT_DIR, 'config/train_config.yaml')
config = load_yaml(TRAIN_CONFIG_PATH)
```

아래는 데이터셋의 경로를 설정해주고 불러오는 과정, random seed를 고정해주는 과정이다.
```python
# DATA
DATASET = config['DIRECTORY']['dataset']
DATA_DIR = os.path.join(PROJECT_DIR, DATASET)

# SEED
RANDOM_SEED = config['SEED']['random_seed']
```

아래는 데이터의 validation set 사이즈, cpu 코어 수 등을 조정하는 작업이다.
```python
VAL_SIZE = config['DATALOADER']['val_size']
NUM_WORKERS = config['DATALOADER']['num_workers']
SHUFFLE = config['DATALOADER']['shuffle']
PIN_MEMORY = config['DATALOADER']['pin_memory']
DROP_LAST = config['DATALOADER']['drop_last']
```

아래는 모델을 학습하는 과정에서 epoch, batch_size, learning_rate 등 하이퍼 파라미터들을 조정하는 과정이다.
```python
EPOCHS = config['TRAIN']['num_epochs']
BATCH_SIZE = config['TRAIN']['batch_size']
LEARNING_RATE = config['TRAIN']['learning_rate']
EARLY_STOPPING_PATIENCE = config['TRAIN']['early_stopping_patience']
```

pycox 모델을 구축할 때 변수 인코딩을 하려면 범주형 변수와 연속형 변수를 구분지어놔야 한다. 이를 위한 작업은 아래와 같다.
```python
COLUMNS_STANDARDIZE = config['COLUMNS']['cols_standardize']
COLUMNS_LEAVE = config['COLUMNS']['cols_leave']
LABELS_ENCODING = config['LABEL_ENCODING']
```

다음 편에서 이어서 작성하도록 한다.

<br>